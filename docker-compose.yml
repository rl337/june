services:
  base:
    build:
      context: .
      dockerfile: ./services/base/Dockerfile
    image: june-base:latest
    profiles:
    - tools
    volumes:
    - /var/log/june/base:/logs
  cli-tools:
    build:
      context: .
      dockerfile: ./services/cli-tools/Dockerfile
    container_name: june-cli-tools
    environment:
    - MODEL_CACHE_DIR=/models
    - HUGGINGFACE_CACHE_DIR=/models/huggingface
    - TRANSFORMERS_CACHE_DIR=/models/transformers
    - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
    - MODEL_NAME=${MODEL_NAME:-Qwen/Qwen3-30B-A3B-Thinking-2507}
    volumes:
    - ${MODEL_CACHE_DIR:-/home/rlee/models}:/models
    - ${JUNE_DATA_DIR:-/home/rlee/june_data}:/data
    - ${JUNE_TEST_DATA_DIR:-/home/rlee/june_test_data}:/test_data
    - ./services/cli-tools/scripts:/app/scripts
    - ./scripts:/app/root_scripts
    - /var/log/june/cli-tools:/logs
    extra_hosts:
    - host.docker.internal:host-gateway
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            device_ids:
            - '0'
            capabilities:
            - gpu
    networks:
    - june_network
    profiles:
    - tools
    command:
    - bash
    - -c
    - 'echo ''CLI Tools container ready. Use: docker exec -it june-cli-tools bash''
      && tail -f /dev/null'
  inference-api:
    build:
      context: .
      dockerfile: ./services/inference-api/Dockerfile
    container_name: june-inference-api
    restart: unless-stopped
    ports:
    - 50051:50051
    environment:
    - MODEL_NAME=${MODEL_NAME:-Qwen/Qwen3-30B-A3B-Thinking-2507}
    - MODEL_DEVICE=${MODEL_DEVICE:-cuda:0}
    - MAX_CONTEXT_LENGTH=${MAX_CONTEXT_LENGTH:-131072}
    - USE_YARN=${USE_YARN:-true}
    - MODEL_TEMPERATURE=${MODEL_TEMPERATURE:-0.7}
    - MODEL_MAX_TOKENS=${MODEL_MAX_TOKENS:-2048}
    - MODEL_TOP_P=${MODEL_TOP_P:-0.9}
    - MODEL_TOP_K=${MODEL_TOP_K:-}
    - MODEL_REPETITION_PENALTY=${MODEL_REPETITION_PENALTY:-}
    - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
    - CUDA_VISIBLE_DEVICES=0
    - CUDA_MPS_ENABLE_PER_CTX_SM_PARTITIONING=1
    - ENABLE_TRACING=${ENABLE_TRACING:-true}
    - JAEGER_ENDPOINT=http://common-jaeger:14268/api/traces
    - JAEGER_AGENT_HOST=common-jaeger
    - JAEGER_AGENT_PORT=6831
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            device_ids:
            - '0'
            capabilities:
            - gpu
    volumes:
    - ${MODEL_CACHE_DIR:-/home/rlee/models}:/models
    - ${JUNE_DATA_DIR:-/home/rlee/june_data}/model_artifacts/inference-api:/app/model_artifacts
    - /var/log/june/inference-api:/logs
    networks:
    - june_network
    - shared-network
  stt:
    build:
      context: .
      dockerfile: ./services/stt/Dockerfile
    restart: unless-stopped
    ports:
    - 50052:50052
    environment:
    - MODEL_NAME=${STT_MODEL:-openai/whisper-large-v3}
    - MODEL_DEVICE=${STT_DEVICE:-cuda:0}
    - MODEL_CACHE_DIR=/models
    - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
    - CUDA_VISIBLE_DEVICES=0
    - CUDA_MPS_ENABLE_PER_CTX_SM_PARTITIONING=1
    - ENABLE_TRACING=${ENABLE_TRACING:-true}
    - JAEGER_ENDPOINT=http://common-jaeger:14268/api/traces
    - JAEGER_AGENT_HOST=common-jaeger
    - JAEGER_AGENT_PORT=6831
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            device_ids:
            - '0'
            capabilities:
            - gpu
    volumes:
    - ${MODEL_CACHE_DIR:-/home/rlee/models}:/models
    - ${JUNE_DATA_DIR:-/home/rlee/june_data}/model_artifacts/stt:/app/model_artifacts
    - /var/log/june/stt:/logs
    healthcheck:
      test:
      - CMD
      - python
      - -c
      - import grpc; grpc.insecure_channel('localhost:50052').check_connectivity_state(True)
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
    - june_network
    - shared-network
  tts:
    build:
      context: .
      dockerfile: ./services/tts/Dockerfile
    restart: unless-stopped
    ports:
    - 50053:50053
    environment:
    - MODEL_NAME=${TTS_MODEL:-facebook/fastspeech2-en-ljspeech}
    - MODEL_DEVICE=${TTS_DEVICE:-cuda:0}
    - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
    - CUDA_VISIBLE_DEVICES=0
    - CUDA_MPS_ENABLE_PER_CTX_SM_PARTITIONING=1
    - ENABLE_TRACING=${ENABLE_TRACING:-true}
    - JAEGER_ENDPOINT=http://common-jaeger:14268/api/traces
    - JAEGER_AGENT_HOST=common-jaeger
    - JAEGER_AGENT_PORT=6831
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            device_ids:
            - '0'
            capabilities:
            - gpu
    volumes:
    - ${MODEL_CACHE_DIR:-/home/rlee/models}:/models
    - ${JUNE_DATA_DIR:-/home/rlee/june_data}/model_artifacts/tts:/app/model_artifacts
    - ./services/tts:/app
    - /var/log/june/tts:/logs
    healthcheck:
      test:
      - CMD
      - python
      - -c
      - import grpc; grpc.insecure_channel('localhost:50053').check_connectivity_state(True)
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
    - june_network
    - shared-network
  telegram:
    build:
      context: .
      dockerfile: ./services/telegram/Dockerfile
    restart: unless-stopped
    ports:
    - 8080:8080
    - 8443:8443
    environment:
    - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
    - TELEGRAM_AUTHORIZED_USERS=${TELEGRAM_AUTHORIZED_USERS:-39833618}
    - CURSOR_AGENT_EXE=/usr/local/bin/cursor-tools/cursor-agent
    - CURSOR_API_KEY=${CURSOR_API_KEY:-}
    - CURSOR_AGENT=1
    - PATH=/usr/local/bin/cursor-tools:${PATH}
    - AGENTICNESS_STATE_DIR=/app/agenticness-state
    - NODE_ENV=development
    - TERM=dumb
    - HOSTNAME=${HOSTNAME:-telegram}
    - TELEGRAM_SERVICE_PORT=8080
    - TELEGRAM_USE_WEBHOOK=${TELEGRAM_USE_WEBHOOK:-false}
    - TELEGRAM_WEBHOOK_URL=${TELEGRAM_WEBHOOK_URL:-}
    - TELEGRAM_WEBHOOK_PORT=8443
    - TELEGRAM_WEBHOOK_PATH=/webhook
    - TELEGRAM_REQUEST_TIMEOUT=${TELEGRAM_REQUEST_TIMEOUT:-30.0}
    - TELEGRAM_RATE_LIMIT_PER_MINUTE=${TELEGRAM_RATE_LIMIT_PER_MINUTE:-10}
    - TELEGRAM_RATE_LIMIT_PER_HOUR=${TELEGRAM_RATE_LIMIT_PER_HOUR:-100}
    - TELEGRAM_RATE_LIMIT_PER_DAY=${TELEGRAM_RATE_LIMIT_PER_DAY:-500}
    - GRPC_MAX_CONNECTIONS_PER_SERVICE=${GRPC_MAX_CONNECTIONS_PER_SERVICE:-10}
    - GRPC_KEEPALIVE_TIME_MS=${GRPC_KEEPALIVE_TIME_MS:-30000}
    - GRPC_KEEPALIVE_TIMEOUT_MS=${GRPC_KEEPALIVE_TIMEOUT_MS:-5000}
    - LOG_LEVEL=${LOG_LEVEL:-INFO}
    - STT_URL=grpc://stt:50052
    - TTS_URL=grpc://tts:50053
    - LLM_URL=grpc://inference-api:50051
    - ENABLE_TRACING=${ENABLE_TRACING:-true}
    - JAEGER_ENDPOINT=http://common-jaeger:14268/api/traces
    - JAEGER_AGENT_HOST=common-jaeger
    - JAEGER_AGENT_PORT=6831
    depends_on:
    - stt
    - tts
    - inference-api
    healthcheck:
      test:
      - CMD
      - wget
      - -q
      - --spider
      - http://localhost:8080/health
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    volumes:
    - ${AGENTICNESS_DIR:-/home/rlee/dev/agenticness}:/app/agenticness:ro
    - ${HOME}/.local/share/cursor-agent/versions/2025.11.06-8fe8a63:/usr/local/bin/cursor-tools:ro
    - ${JUNE_DATA_DIR:-/home/rlee/june_data}/agenticness-state:/app/agenticness-state
    - ${HOME}/.config/cursor/auth.json:/home/june/.config/cursor/auth.json:ro
    - ${JUNE_DATA_DIR:-/home/rlee/june_data}/cursor-container-config:/home/june/.config/cursor:rw
    - ./config/cursor-mcp-config.json:/home/june/.config/cursor/mcp.json:ro
    - ${HOME}/.cursor:/home/june/.cursor:rw
    - /var/log/june/telegram:/logs
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    networks:
    - june_network
    - shared-network
  discord:
    build:
      context: .
      dockerfile: ./services/discord/Dockerfile
    restart: unless-stopped
    ports:
    - 8081:8081
    environment:
    - DISCORD_BOT_TOKEN=${DISCORD_BOT_TOKEN:-}
    - DISCORD_AUTHORIZED_USERS=${DISCORD_AUTHORIZED_USERS:-}
    - CURSOR_AGENT_EXE=/usr/local/bin/cursor-tools/cursor-agent
    - CURSOR_API_KEY=${CURSOR_API_KEY:-}
    - CURSOR_AGENT=1
    - PATH=/usr/local/bin/cursor-tools:${PATH}
    - AGENTICNESS_STATE_DIR=/app/agenticness-state
    - NODE_ENV=development
    - TERM=dumb
    - HOSTNAME=${HOSTNAME:-discord}
    - DISCORD_SERVICE_PORT=8081
    - GRPC_MAX_CONNECTIONS_PER_SERVICE=${GRPC_MAX_CONNECTIONS_PER_SERVICE:-10}
    - GRPC_KEEPALIVE_TIME_MS=${GRPC_KEEPALIVE_TIME_MS:-30000}
    - GRPC_KEEPALIVE_TIMEOUT_MS=${GRPC_KEEPALIVE_TIMEOUT_MS:-5000}
    - LOG_LEVEL=${LOG_LEVEL:-INFO}
    - STT_URL=grpc://stt:50052
    - TTS_URL=grpc://tts:50053
    - LLM_URL=grpc://inference-api:50051
    - ENABLE_TRACING=${ENABLE_TRACING:-true}
    - JAEGER_ENDPOINT=http://common-jaeger:14268/api/traces
    - JAEGER_AGENT_HOST=common-jaeger
    - JAEGER_AGENT_PORT=6831
    depends_on:
    - stt
    - tts
    - inference-api
    volumes:
    - ${AGENTICNESS_DIR:-/home/rlee/dev/agenticness}:/app/agenticness:ro
    - ${HOME}/.local/share/cursor-agent/versions/2025.11.06-8fe8a63:/usr/local/bin/cursor-tools:ro
    - ${JUNE_DATA_DIR:-/home/rlee/june_data}/agenticness-state:/app/agenticness-state
    - ${HOME}/.config/cursor/auth.json:/home/june/.config/cursor/auth.json:ro
    - ${JUNE_DATA_DIR:-/home/rlee/june_data}/cursor-container-config:/home/june/.config/cursor:rw
    - ./config/cursor-mcp-config.json:/home/june/.config/cursor/mcp.json:ro
    - ${HOME}/.cursor:/home/june/.cursor:rw
    - /var/log/june/discord:/logs
    networks:
    - june_network
    - shared-network
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:8081/health
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
networks:
  june_network:
    driver: bridge
  shared-network:
    external: true
    name: shared_network
