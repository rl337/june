# Docker Secrets Configuration
# To use Docker secrets, create them first:
#   echo "your-password" | docker secret create postgres_password -
#   echo "your-key" | docker secret create encryption_key -
#   echo "your-token" | docker secret create telegram_bot_token -
#
# Then uncomment the secrets: sections in services below
# and update environment variables to use *_FILE paths

services:
  # Base build image target (not a running service)
  base:
    build:
      context: .
      dockerfile: ./services/base/Dockerfile
    image: june-base:latest
    profiles:
      - tools
  # PostgreSQL with pgvector extension for RAG
  postgres:
    image: pgvector/pgvector:pg16
    container_name: june-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: june
      POSTGRES_USER: june
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-changeme}
      # For Docker secrets, use: POSTGRES_PASSWORD_FILE=/run/secrets/postgres_password
    # secrets:
    #   - postgres_password
    ports:
      - "5432:5432"
    volumes:
      - ${JUNE_DATA_DIR:-/home/rlee/june_data}/postgres:/var/lib/postgresql/data
      - ./config/postgres-init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U june"]
      interval: 10s
      timeout: 5s
      retries: 5

  # MinIO for object storage (S3-compatible)
  minio:
    image: minio/minio:latest
    container_name: june-minio
    restart: unless-stopped
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-admin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-changeme}
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ${JUNE_DATA_DIR:-/home/rlee/june_data}/minio:/data
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  # NATS for pub/sub messaging
  nats:
    image: nats:latest
    container_name: june-nats
    restart: unless-stopped
    ports:
      - "4222:4222"
      - "8222:8222"  # HTTP monitoring
    command: ["-js", "-m", "8222"]
    volumes:
      - ${JUNE_DATA_DIR:-/home/rlee/june_data}/nats/data:/data
      - ${JUNE_DATA_DIR:-/home/rlee/june_data}/nats/jets_stream:/store
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8222/healthz"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for caching
  redis:
    image: redis:7-alpine
    container_name: june-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - ${JUNE_DATA_DIR:-/home/rlee/june_data}/redis:/data
    command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - june_network

  # Prometheus for metrics
  prometheus:
    image: prom/prometheus:latest
    container_name: june-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./config/prometheus-alerts.yml:/etc/prometheus/prometheus-alerts.yml
      - ${JUNE_DATA_DIR:-/home/rlee/june_data}/prometheus:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    depends_on:
      - node-exporter
      - postgres-exporter
    networks:
      - june_network

  # Node Exporter for system metrics (CPU, memory, disk)
  node-exporter:
    image: prom/node-exporter:latest
    container_name: june-node-exporter
    restart: unless-stopped
    ports:
      - "9100:9100"
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--path.rootfs=/rootfs'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
      - '--collector.netstat'
      - '--collector.network'
      - '--collector.cpu'
      - '--collector.meminfo'
      - '--collector.diskstats'
      - '--collector.filesystem'
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    networks:
      - june_network

  # PostgreSQL Exporter for database metrics
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: june-postgres-exporter
    restart: unless-stopped
    ports:
      - "9187:9187"
    environment:
      DATA_SOURCE_NAME: "postgresql://june:${POSTGRES_PASSWORD:-changeme}@postgres:5432/june?sslmode=disable"
    depends_on:
      - postgres
    networks:
      - june_network

  # Grafana for dashboards
  grafana:
    image: grafana/grafana:latest
    container_name: june-grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin}
    volumes:
      - ${JUNE_DATA_DIR:-/home/rlee/june_data}/grafana:/var/lib/grafana
      - ./config/grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      - prometheus

  # TODO MCP Service (Standalone task management service)
  todo-mcp-service:
    build:
      context: .
      dockerfile: ./services/todo-service/Dockerfile
    container_name: june-todo-mcp-service
    restart: unless-stopped
    ports:
      - "5080:8004"
    environment:
      - TODO_DB_PATH=/app/data/todos.db
      - TODO_BACKUPS_DIR=/app/backups
      - TODO_SERVICE_PORT=8004
      - TODO_BACKUP_INTERVAL_HOURS=24
    volumes:
      - ${JUNE_DATA_DIR:-/home/rlee/june_data}/todo-mcp-service/data:/app/data
      - ${JUNE_DATA_DIR:-/home/rlee/june_data}/todo-mcp-service/backups:/app/backups
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8004/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - june_network

  # Knowledge Graph MCP Service
  knowledge-graph:
    build:
      context: .
      dockerfile: ./services/knowledge-graph/Dockerfile
    container_name: june-knowledge-graph
    restart: unless-stopped
    ports:
      - "8006:8006"
    environment:
      - KG_DB_PATH=/app/data/kg.db
      - KG_SERVICE_PORT=8006
    volumes:
      - ${JUNE_DATA_DIR:-/home/rlee/june_data}/knowledge-graph/data:/app/data
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8006/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - june_network

  # Document Manager MCP Service
  document-manager:
    build:
      context: .
      dockerfile: ./services/document-manager/Dockerfile
    container_name: june-document-manager
    restart: unless-stopped
    ports:
      - "8007:8007"
    environment:
      - DOC_DB_PATH=/app/data/documents.db
      - DOC_SERVICE_PORT=8007
    volumes:
      - ${JUNE_DATA_DIR:-/home/rlee/june_data}/document-manager/data:/app/data
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8007/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - june_network

  # Orchestration Service (Agent orchestration and coordination)
  orchestrator:
    build:
      context: ./services/orchestrator
      dockerfile: Dockerfile
    container_name: june-orchestrator
    restart: unless-stopped
    ports:
      - "8005:8005"
    environment:
      - ORCHESTRATOR_PORT=8005
      - TODO_SERVICE_URL=http://todo-mcp-service:8004
      - GATEWAY_URL=http://gateway:8000
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    depends_on:
      - todo-mcp-service
      - gateway
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8005/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - june_network

  # Webapp Service (React Chat Interface)
  webapp:
    build:
      context: ./services/webapp
      dockerfile: Dockerfile
    container_name: june-webapp
    restart: unless-stopped
    ports:
      - "3001:3000"  # React dev server
    environment:
      - REACT_APP_GATEWAY_URL=http://localhost:8000
      - REACT_APP_WS_URL=ws://localhost:8000
    depends_on:
      - gateway
    volumes:
      - ./services/webapp:/app
      - /app/node_modules
    networks:
      - june_network

  # Loki for log aggregation
  loki:
    image: grafana/loki:latest
    container_name: june-loki
    restart: unless-stopped
    ports:
      - "3100:3100"
    volumes:
      - ./config/loki-config.yml:/etc/loki/local-config.yaml
      - ${JUNE_DATA_DIR:-/home/rlee/june_data}/loki:/loki

  # Jaeger for distributed tracing
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: june-jaeger
    restart: unless-stopped
    ports:
      - "16686:16686"  # UI
      - "14268:14268"  # Agent endpoint
      - "6831:6831/udp"  # UDP agent
      - "6832:6832/udp"
    environment:
      - COLLECTOR_ZIPKIN_HOST_PORT=:9411

  # CLI Tools Container for development and maintenance
  cli-tools:
    build:
      context: .
      dockerfile: ./services/cli-tools/Dockerfile
    container_name: june-cli-tools
    environment:
      - MODEL_CACHE_DIR=/models
      - HUGGINGFACE_CACHE_DIR=/models/huggingface
      - TRANSFORMERS_CACHE_DIR=/models/transformers
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
    volumes:
      - ${MODEL_CACHE_DIR:-/home/rlee/models}:/models
      - ${JUNE_DATA_DIR:-/home/rlee/june_data}:/data
      - ${JUNE_TEST_DATA_DIR:-/home/rlee/june_test_data}:/test_data
      - ./services/cli-tools/scripts:/app/scripts
      - ./scripts:/app/root_scripts
      - ./services/gateway/tests:/app/gateway_tests
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - june_network
    profiles:
      - tools
    command: ["bash", "-c", "echo 'CLI Tools container ready. Use: docker exec -it june-cli-tools bash' && tail -f /dev/null"]

  # Mock Sink - records requests for downstream validation
  mock-sink:
    build:
      context: ./services/mock-sink
      dockerfile: Dockerfile
    container_name: june-mock-sink
    restart: unless-stopped
    ports:
      - "7000:7000"
    volumes:
      - ${JUNE_DATA_DIR:-/home/rlee/june_data}/model_artifacts/mock-sink:/app/model_artifacts
    networks:
      - june_network
    profiles:
      - tools

  # Nginx Load Balancer (frontend for Gateway service)
  nginx:
    image: nginx:alpine
    container_name: june-nginx
    restart: unless-stopped
    ports:
      - "8000:80"   # HTTP (load balanced Gateway)
      - "8001:8001" # WebSocket (load balanced Gateway)
    volumes:
      - ./config/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - gateway
    networks:
      - june_network
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost/nginx-health"]
      interval: 10s
      timeout: 5s
      retries: 3

  # Gateway service (FastAPI + WebSocket) - Scalable
  # Scale with: docker compose up --scale gateway=3
  gateway:
    build:
      context: .
      dockerfile: ./services/gateway/Dockerfile
    # container_name removed to allow scaling
    restart: unless-stopped
    # Ports removed - nginx handles external access
    # Internal port 8000 is still exposed within Docker network
    expose:
      - "8000"
    environment:
      - INFERENCE_API_URL=grpc://inference-api:50051
      - STT_URL=grpc://stt:50052
      - TTS_URL=grpc://tts:50053
      - NATS_URL=nats://nats:4222
      - POSTGRES_URL=postgresql://june:${POSTGRES_PASSWORD:-changeme}@postgres:5432/june
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ROOT_USER:-admin}
      - MINIO_SECRET_KEY=${MINIO_ROOT_PASSWORD:-changeme}
      - REDIS_URL=redis://redis:6379/0
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - JWT_SECRET=${JWT_SECRET:-change-this-secret}
      - ENCRYPTION_KEY=${ENCRYPTION_KEY:-}
      - ENABLE_DB_ENCRYPTION=${ENABLE_DB_ENCRYPTION:-true}
      # For Docker secrets, use: ENCRYPTION_KEY_FILE=/run/secrets/encryption_key
    # secrets:
    #   - encryption_key
    #   - telegram_bot_token
    depends_on:
      - nats
      - postgres
      - minio
      - redis
    volumes:
      - ${JUNE_DATA_DIR:-/home/rlee/june_data}/model_artifacts/gateway:/app/model_artifacts
      - ./services/gateway:/app
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - june_network

  # Inference API Coordinator (Primary GPU workload)
  inference-api:
    build:
      context: .
      dockerfile: ./services/inference-api/Dockerfile
    container_name: june-inference-api
    restart: unless-stopped
    ports:
      - "50051:50051"  # gRPC
    environment:
      - MODEL_NAME=${MODEL_NAME:-Qwen/Qwen3-30B-A3B-Thinking-2507}
      - MODEL_DEVICE=${MODEL_DEVICE:-cuda:0}
      - MAX_CONTEXT_LENGTH=${MAX_CONTEXT_LENGTH:-131072}
      - USE_YARN=${USE_YARN:-true}
      - MODEL_TEMPERATURE=${MODEL_TEMPERATURE:-0.7}
      - MODEL_MAX_TOKENS=${MODEL_MAX_TOKENS:-2048}
      - MODEL_TOP_P=${MODEL_TOP_P:-0.9}
      - MODEL_TOP_K=${MODEL_TOP_K:-}
      - MODEL_REPETITION_PENALTY=${MODEL_REPETITION_PENALTY:-}
      - POSTGRES_URL=postgresql://june:${POSTGRES_PASSWORD:-changeme}@postgres:5432/june
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ROOT_USER:-admin}
      - MINIO_SECRET_KEY=${MINIO_ROOT_PASSWORD:-changeme}
      - NATS_URL=nats://nats:4222
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
      - CUDA_VISIBLE_DEVICES=0
      - CUDA_MPS_ENABLE_PER_CTX_SM_PARTITIONING=1
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    depends_on:
      - postgres
      - minio
      - nats
    volumes:
      - ${MODEL_CACHE_DIR:-/home/rlee/models}:/models
      - ${JUNE_DATA_DIR:-/home/rlee/june_data}/model_artifacts/inference-api:/app/model_artifacts
    networks:
      - june_network

  # STT Service (Speech-to-Text) - Scalable
  # Scale with: docker compose up --scale stt=2
  # Note: GPU scaling requires multiple GPUs or MPS partitioning
  stt:
    build:
      context: .
      dockerfile: ./services/stt/Dockerfile
    # container_name removed to allow scaling
    restart: unless-stopped
    # Port mapping kept for direct gRPC access, but service is scalable
    # Docker Compose will handle port conflicts when scaling
    ports:
      - "50052:50052"  # gRPC (first instance only)
    environment:
      - MODEL_NAME=${STT_MODEL:-openai/whisper-large-v3}
      - MODEL_DEVICE=${STT_DEVICE:-cuda:0}
      - MODEL_CACHE_DIR=/models
      - NATS_URL=nats://nats:4222
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
      - CUDA_VISIBLE_DEVICES=0
      - CUDA_MPS_ENABLE_PER_CTX_SM_PARTITIONING=1
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    depends_on:
      - nats
    volumes:
      - ${MODEL_CACHE_DIR:-/home/rlee/models}:/models
      - ${JUNE_DATA_DIR:-/home/rlee/june_data}/model_artifacts/stt:/app/model_artifacts
    healthcheck:
      test: ["CMD", "python", "-c", "import grpc; grpc.insecure_channel('localhost:50052').check_connectivity_state(True)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - june_network

  # TTS Service (Text-to-Speech) - Scalable
  # Scale with: docker compose up --scale tts=2
  # Note: GPU scaling requires multiple GPUs or MPS partitioning
  tts:
    build:
      context: .
      dockerfile: ./services/tts/Dockerfile
    # container_name removed to allow scaling
    restart: unless-stopped
    # Port mapping kept for direct gRPC access, but service is scalable
    # Docker Compose will handle port conflicts when scaling
    ports:
      - "50053:50053"  # gRPC (first instance only)
    environment:
      - MODEL_NAME=${TTS_MODEL:-facebook/fastspeech2-en-ljspeech}
      - MODEL_DEVICE=${TTS_DEVICE:-cuda:0}
      - NATS_URL=nats://nats:4222
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
      - CUDA_VISIBLE_DEVICES=0
      - CUDA_MPS_ENABLE_PER_CTX_SM_PARTITIONING=1
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    depends_on:
      - nats
    volumes:
      - ${MODEL_CACHE_DIR:-/home/rlee/models}:/models
      - ${JUNE_DATA_DIR:-/home/rlee/june_data}/model_artifacts/tts:/app/model_artifacts
      - ./services/tts:/app
    healthcheck:
      test: ["CMD", "python", "-c", "import grpc; grpc.insecure_channel('localhost:50053').check_connectivity_state(True)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - june_network

  # Telegram Bot Service - Scalable
  # Scale with: docker compose up --scale telegram=2
  # Note: Only one instance should handle webhook if using webhook mode
  telegram:
    build:
      context: .
      dockerfile: ./services/telegram/Dockerfile
    # container_name removed to allow scaling
    restart: unless-stopped
    # Port mapping kept for direct access, but service is scalable
    # Docker Compose will handle port conflicts when scaling
    # For webhook mode, ensure only one instance is configured
    ports:
      - "8080:8080"
      - "8443:8443"  # Webhook port (if using webhook mode)
    environment:
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_AUTHORIZED_USERS=${TELEGRAM_AUTHORIZED_USERS:-39833618}
      - TODO_SERVICE_URL=http://todo-mcp-service:8004
      - CURSOR_AGENT_EXE=/usr/local/bin/cursor-tools/cursor-agent
      - CURSOR_API_KEY=${CURSOR_API_KEY:-}
      - CURSOR_AGENT=1
      - PATH=/usr/local/bin/cursor-tools:${PATH}
      - AGENTICNESS_STATE_DIR=/app/agenticness-state
      - NODE_ENV=development
      - TERM=dumb
      - HOSTNAME=${HOSTNAME:-telegram}
      - TELEGRAM_SERVICE_PORT=8080
      - TELEGRAM_USE_WEBHOOK=${TELEGRAM_USE_WEBHOOK:-false}
      - TELEGRAM_WEBHOOK_URL=${TELEGRAM_WEBHOOK_URL:-}
      - TELEGRAM_WEBHOOK_PORT=8443
      - TELEGRAM_WEBHOOK_PATH=/webhook
      - TELEGRAM_REQUEST_TIMEOUT=${TELEGRAM_REQUEST_TIMEOUT:-30.0}
      - TELEGRAM_RATE_LIMIT_PER_MINUTE=${TELEGRAM_RATE_LIMIT_PER_MINUTE:-10}
      - TELEGRAM_RATE_LIMIT_PER_HOUR=${TELEGRAM_RATE_LIMIT_PER_HOUR:-100}
      - TELEGRAM_RATE_LIMIT_PER_DAY=${TELEGRAM_RATE_LIMIT_PER_DAY:-500}
      - GRPC_MAX_CONNECTIONS_PER_SERVICE=${GRPC_MAX_CONNECTIONS_PER_SERVICE:-10}
      - GRPC_KEEPALIVE_TIME_MS=${GRPC_KEEPALIVE_TIME_MS:-30000}
      - GRPC_KEEPALIVE_TIMEOUT_MS=${GRPC_KEEPALIVE_TIMEOUT_MS:-5000}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - STT_URL=grpc://stt:50052
      - TTS_URL=grpc://tts:50053
      - LLM_URL=grpc://inference-api:50051
      - NATS_URL=nats://nats:4222
      - USE_VOICE_QUEUE=${USE_VOICE_QUEUE:-false}
    depends_on:
      - stt
      - tts
      - inference-api
      - nats
      - todo-mcp-service
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    volumes:
      - ${AGENTICNESS_DIR:-/home/rlee/dev/agenticness}:/app/agenticness:ro
      - ${HOME}/.local/share/cursor-agent/versions/2025.11.06-8fe8a63:/usr/local/bin/cursor-tools:ro
      - ${JUNE_DATA_DIR:-/home/rlee/june_data}/agenticness-state:/app/agenticness-state
      - ${HOME}/.config/cursor/auth.json:/home/june/.config/cursor/auth.json:ro
      - ${JUNE_DATA_DIR:-/home/rlee/june_data}/cursor-container-config:/home/june/.config/cursor:rw
      - ./config/cursor-mcp-config.json:/home/june/.config/cursor/mcp.json:ro
      - ${HOME}/.cursor:/home/june/.cursor:rw
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    networks:
      - june_network

  # Discord Bot Service
  discord:
    build:
      context: .
      dockerfile: ./services/discord/Dockerfile
    restart: unless-stopped
    ports:
      - "8081:8081"
    environment:
      - DISCORD_BOT_TOKEN=${DISCORD_BOT_TOKEN:-}
      - DISCORD_AUTHORIZED_USERS=${DISCORD_AUTHORIZED_USERS:-}
      - TODO_SERVICE_URL=http://todo-mcp-service:8004
      - CURSOR_AGENT_EXE=/usr/local/bin/cursor-tools/cursor-agent
      - CURSOR_API_KEY=${CURSOR_API_KEY:-}
      - CURSOR_AGENT=1
      - PATH=/usr/local/bin/cursor-tools:${PATH}
      - AGENTICNESS_STATE_DIR=/app/agenticness-state
      - NODE_ENV=development
      - TERM=dumb
      - HOSTNAME=${HOSTNAME:-discord}
      - DISCORD_SERVICE_PORT=8081
      - GRPC_MAX_CONNECTIONS_PER_SERVICE=${GRPC_MAX_CONNECTIONS_PER_SERVICE:-10}
      - GRPC_KEEPALIVE_TIME_MS=${GRPC_KEEPALIVE_TIME_MS:-30000}
      - GRPC_KEEPALIVE_TIMEOUT_MS=${GRPC_KEEPALIVE_TIMEOUT_MS:-5000}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - STT_URL=grpc://stt:50052
      - TTS_URL=grpc://tts:50053
      - LLM_URL=grpc://inference-api:50051
    depends_on:
      - stt
      - tts
      - inference-api
    volumes:
      - ${AGENTICNESS_DIR:-/home/rlee/dev/agenticness}:/app/agenticness:ro
      - ${HOME}/.local/share/cursor-agent/versions/2025.11.06-8fe8a63:/usr/local/bin/cursor-tools:ro
      - ${JUNE_DATA_DIR:-/home/rlee/june_data}/agenticness-state:/app/agenticness-state
      - ${HOME}/.config/cursor/auth.json:/home/june/.config/cursor/auth.json:ro
      - ${JUNE_DATA_DIR:-/home/rlee/june_data}/cursor-container-config:/home/june/.config/cursor:rw
      - ./config/cursor-mcp-config.json:/home/june/.config/cursor/mcp.json:ro
      - ${HOME}/.cursor:/home/june/.cursor:rw
    networks:
      - june_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Voice Message Queue Workers (scale horizontally with: docker compose up --scale telegram-voice-worker=2)
  telegram-voice-worker:
    build:
      context: .
      dockerfile: ./services/telegram/Dockerfile
    restart: unless-stopped
    command: ["python", "voice_worker.py"]
    environment:
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - STT_URL=grpc://stt:50052
      - TTS_URL=grpc://tts:50053
      - LLM_URL=grpc://inference-api:50051
      - NATS_URL=nats://nats:4222
      - WORKER_ID=worker-${HOSTNAME}
    depends_on:
      - nats
      - stt
      - tts
      - inference-api
    networks:
      - june_network
    profiles:
      - workers

networks:
  june_network:
    driver: bridge

# Docker Secrets (uncomment to use)
# secrets:
#   postgres_password:
#     external: true
#   encryption_key:
#     external: true
#   telegram_bot_token:
#     external: true
#   jwt_secret:
#     external: true

# All data volumes now use bind mounts to /home/rlee/june_data
# Named volumes removed - data is stored in host filesystem

